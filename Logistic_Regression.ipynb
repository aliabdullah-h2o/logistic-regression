{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ_L9aKKSC7o"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYXWobwFTpNf",
        "outputId": "dbe7a06f-db00-48b5-b8bb-7a0400af1173"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "class LogisticRegression:\n",
        "\n",
        "    def __init__(self, learning_rate=0.02, n_iters=1000000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # init parameters\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "        self.y_predicted = np.zeros(n_samples)\n",
        "\n",
        "        # gradient descent\n",
        "        for _ in range(self.n_iters):\n",
        "            # approximate y with linear combination of weights and x, plus bias\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            # apply sigmoid function\n",
        "            y_predicted = self._sigmoid(linear_model)\n",
        "\n",
        "            # compute gradients\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
        "            # update parameters\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self._sigmoid(linear_model)\n",
        "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "        return np.array(y_predicted_cls)\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    \n",
        "df = pd.read_csv(\"candy-data.csv\")\n",
        "regrDF= df[['sugarpercent',\"pricepercent\",'chocolate']]\n",
        "\n",
        "x_train = np.zeros((63,2),dtype=\"float\")\n",
        "x_test = np.zeros((22,2),dtype=\"float\")\n",
        "y_train = np.zeros(63)\n",
        "y_test = np.zeros(22)\n",
        "\n",
        "x_train[:,:] = regrDF.iloc[0:63,:2]\n",
        "y_train[:] =  regrDF.iloc[0:63,2]\n",
        "x_test[:,:] = regrDF.iloc[63:85,:2]\n",
        "y_test[:] =  regrDF.iloc[63:85,2]\n",
        "\n",
        "lg = LogisticRegression() \n",
        "lg.fit(x_train,y_train)\n",
        "y_predicted = lg.predict(x_test)\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test,y_predicted))\n",
        "print(lg.weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7272727272727273\n",
            "[-0.73849307  4.7566111 ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}